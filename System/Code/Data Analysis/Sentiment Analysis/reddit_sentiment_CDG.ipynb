{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import statistics\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the data loaded for sentiment analysis\n",
    "df_clean_cat_bcovid = pd.read_csv(r'df_clean_cat_bcovid.csv')\n",
    "df_clean_cat_acovid = pd.read_csv(r'df_clean_cat_acovid.csv')\n",
    "\n",
    "# This is the training data for LSTM model\n",
    "df = pd.read_csv('Twitter_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_cat_all = pd.concat([df_clean_cat_bcovid,df_clean_cat_acovid], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data to identify sentitments with Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...  Negative\n",
       "1  talk all the nonsense and continue all the dra...   Neutral\n",
       "2  what did just say vote for modi  welcome bjp t...  Positive\n",
       "3  asking his supporters prefix chowkidar their n...  Positive\n",
       "4  answer who among these the most powerful world...  Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop missing rows\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Map tweet categories\n",
    "df['category'] = df['category'].map({-1.0:'Negative', 0.0:'Neutral', 1.0:'Positive'})\n",
    "# Output first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original tweet -> when modi promised “minimum government maximum governance” expected him begin the difficult job reforming the state why does take years get justice state should and not business and should exit psus and temples\n",
      "\n",
      "Processed tweet -> ['modi', 'promis', 'minimum', 'govern', 'maximum', 'govern', 'expect', 'begin', 'difficult', 'job', 'reform', 'state', 'take', 'year', 'get', 'justic', 'state', 'busi', 'exit', 'psu', 'templ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ivyha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re    # RegEx for removing non-letter characters\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "\n",
    "def tweet_to_words(tweet):\n",
    "    ''' Convert tweet text into a sequence of words '''\n",
    "    \n",
    "    # convert to lowercase\n",
    "    text = tweet.lower()\n",
    "    # remove non letters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    # tokenize\n",
    "    words = text.split()\n",
    "    # remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    # apply stemming\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    # return list\n",
    "    return words\n",
    "\n",
    "print(\"\\nOriginal tweet ->\", df['clean_text'][0])\n",
    "print(\"\\nProcessed tweet ->\", tweet_to_words(df['clean_text'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Function to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data processing to each tweet\n",
    "X = list(map(tweet_to_words, df['clean_text']))\n",
    "\n",
    "max_words = 5000\n",
    "max_len=50\n",
    "\n",
    "def tokenize_pad_sequences(text):\n",
    "    '''\n",
    "    This function tokenize the input text into sequnences of intergers and then\n",
    "    pad each sequence to the same length\n",
    "    '''\n",
    "    # Text tokenization\n",
    "    tokenizer = Tokenizer(num_words=max_words, lower=True, split=' ')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    # Transforms text to a sequence of integers\n",
    "    X = tokenizer.texts_to_sequences(text)\n",
    "    # Pad sequences to the same length\n",
    "    X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "    # return sequences\n",
    "    return X, tokenizer\n",
    "\n",
    "print('Before Tokenization & Padding \\n', df['clean_text'][0])\n",
    "X, tokenizer = tokenize_pad_sequences(df['clean_text'])\n",
    "print('After Tokenization & Padding \\n', X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set -> (114078, 50) (114078, 3)\n",
      "Validation Set -> (1000, 50) (1000, 3)\n",
      "Test Set -> (113078, 50) (113078, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical variable into dummy/indicator variables.\n",
    "y = pd.get_dummies(df['category'])\n",
    "# Train and Test split\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "# Extracting validation set from the train set\n",
    "valid_size=1000\n",
    "X_valid, y_valid = X_train[-valid_size:], y_train[-valid_size:]\n",
    "X_test, y_test = X_train[:-valid_size], y_train[:-valid_size]\n",
    "\n",
    "print('Train Set ->', X_train.shape, y_train.shape)\n",
    "print('Validation Set ->', X_valid.shape, y_valid.shape)\n",
    "print('Test Set ->', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Function to Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    ''' Function to calculate f1 score '''\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy\n",
    "\n",
    "#### Precision = True Positive/(True Positive + False Positive)\n",
    "\n",
    "Ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    "\n",
    "#### Recall = True Positive/(True Positive + False Negative)\n",
    "\n",
    "Ratio of correctly predicted positive observations to all the actual positive observations.\n",
    "\n",
    "#### Accuracy = (True Positive + True Negative)/(True Positive + False Positive + False Negative + True Negative)\n",
    "\n",
    "A ratio of correctly predicted observation to the total observations.\n",
    "\n",
    "#### F1 Score = 2*((Precision*Recall)/(Precision + Recall))\n",
    "\n",
    "Weighted average of Precision and Recall. Needed when you want to seek balance between Precision and Recall.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 32)            160000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 50, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 25, 32)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 179,939\n",
      "Trainable params: 179,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "3565/3565 [==============================] - 56s 15ms/step - loss: 0.3106 - accuracy: 0.8967 - precision: 0.9163 - recall: 0.8778 - val_loss: 0.1886 - val_accuracy: 0.9420 - val_precision: 0.9438 - val_recall: 0.9410\n",
      "\n",
      "CNN + LSTM Accuracy  : 94.81 %\n",
      "CNN + LSTM Precision : 94.98 %\n",
      "CNN + LSTM Recall    : 94.62 %\n",
      "CNN + LSTM F1 Score  : 94.80 %\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 32\n",
    "\n",
    "# Build model\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size, embedding_size, input_length=max_len))\n",
    "model3.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=2))\n",
    "model3.add(Bidirectional(LSTM(32)))\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Dense(3, activation='softmax'))\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "# Compile model\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "               metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Train model\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "history3 = model3.fit(X_train, y_train,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                      batch_size=batch_size, epochs=num_epochs)\n",
    "\n",
    "# Evaluate model on the test set\n",
    "loss, accuracy, precision, recall = model3.evaluate(X_test, y_test, verbose=0)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('CNN + LSTM Accuracy  : {:.2f}'.format(100 * accuracy), '%')\n",
    "print('CNN + LSTM Precision : {:.2f}'.format(100 * precision), '%')\n",
    "print('CNN + LSTM Recall    : {:.2f}'.format(100 * recall), '%')\n",
    "print('CNN + LSTM F1 Score  : {:.2f}'.format(f1_score(precision, recall)), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LSTM Function to Execute Trained Model for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(text):\n",
    "    '''Function to predict sentiment class of the passed text'''\n",
    "    \n",
    "    sentiment_classes = ['Negative', 'Neutral', 'Positive']\n",
    "    max_len=50\n",
    "    \n",
    "    # Transforms text to a sequence of integers using a tokenizer object\n",
    "    xt = tokenizer.texts_to_sequences(text)\n",
    "    # Pad sequences to the same length\n",
    "    xt = pad_sequences(xt, padding='post', maxlen=max_len)\n",
    "    # Do the prediction using the loaded model\n",
    "    yt = model3.predict(xt).argmax(axis=1)\n",
    "    # Print the predicted sentiment\n",
    "    # Print('The predicted sentiment is', sentiment_classes[yt[0]])  \n",
    "    return sentiment_classes[yt[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_text(df):\n",
    "    sent = []\n",
    "\n",
    "    for t in df['text']: \n",
    "        sent.append(predict_class([t]))\n",
    "\n",
    "    df['sentiment'] = sent      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute LSTM Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis will be run on bcovid, acovid, and all dataframes. \n",
    "This also applies for all visualizations done later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_text(df_clean_cat_bcovid)\n",
    "sentiment_text(df_clean_cat_acovid)\n",
    "sentiment_text(df_clean_cat_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Sentiment Frequncy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_bcovid[df_clean_cat_bcovid['category'] == 'bus'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments Before Covid')\n",
    "sns.color_palette('pastel')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_acovid[df_clean_cat_acovid['category'] == 'bus'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_all[df_clean_cat_all['category'] == 'bus'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_bcovid[df_clean_cat_bcovid['category'] == 'mrt'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments Before Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_acovid[df_clean_cat_acovid['category'] == 'mrt'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_all[df_clean_cat_all['category'] == 'mrt'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_bcovid[df_clean_cat_bcovid['category'] == 'taxi'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments Before Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_acovid[df_clean_cat_acovid['category'] == 'taxi'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_all[df_clean_cat_all['category'] == 'taxi'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_bcovid[df_clean_cat_bcovid['category'] == 'private hire'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments Before Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_acovid[df_clean_cat_acovid['category'] == 'private hire'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_all[df_clean_cat_all['category'] == 'private hire'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_bcovid[df_clean_cat_bcovid['category'] == 'car rental'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments Before Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_acovid[df_clean_cat_acovid['category'] == 'car rental'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "ax = sns.countplot(x = 'sentiment', data = df_clean_cat_all[df_clean_cat_all['category'] == 'car rental'],\n",
    "                   order = ['Negative', 'Neutral', 'Positive'], palette = ['#ad5353', '#5985b5', '#87c993'])\n",
    "ax.set_title('Sentiments After Covid')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Negative Discussions\n",
    "\n",
    "Here, we will preview the negatives discussions by looking at the top few discussions and looking at the word cloud of negatives discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_neg(data, stopword, cat):\n",
    "    t = data[data['sentiment']=='Negative']\n",
    "    p = t[t['category'] == cat]\n",
    "\n",
    "    message = p['text'].tolist()\n",
    "    \n",
    "    text = \" \".join(list(message))\n",
    "\n",
    "    wc = WordCloud(stopwords = stopword, background_color='white').generate(text)\n",
    "\n",
    "    plt.imshow(wc, interpolation = 'bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['mrt', 'station', 'see', 'bus', 'buses', 'line', 'account', 'one', 'full',\n",
    "                  'get', 'min', 'class', 'year', 'pm', '', 'take', 'taxi', 'allow', 'last', 'almost',\n",
    "                  'post', 'start', 'cross', 'car_rental', 'comfortdelgro', 'singapore', 'grab',\n",
    "                  'night', 'find', 'need', 'build', 'photo', 'video', 'leave', 'car', 'train', \n",
    "                  'think', 'food', 'make', 'set', 'fresh', 'sbs', 'driver', 'delgro', 'comfort',  \n",
    "                  'move',  'ever', 'blue', 'uber', 'go', 'look', 'use', 'also', 'give', \n",
    "                  'many', 'come', 'lot', 'seem', 'guess', 'definitely', 'sure', 'keep', 'much', 'already', \n",
    "                  'do', 'lol', 'people', 'well', 'back', 'week', 'u', 'want', 'day', 'will', 'know', \n",
    "                  'even', 'really', 'said', 'say', 'cab', 'public transport', 'taxis', 'public', \n",
    "                  'transport', 'thing', 'still', 'got', 'now', 's', 'stop', 'around', 'another', 'stations',\n",
    "                  'smrt', 'next', 'us', 'may', 'person', 'years', 'going', 'trains', 'way', 'etc', 'makes',\n",
    "                  'seat', 'guy', 'https', 'always', 'riders', 'cabbie', 'sg', 'drivers', 'auntie', 'man', \n",
    "                  'uncle', 'stops', 'someone', 'something', 'andy', 'cabs', 'cabbies', 'order', 'delivery', \n",
    "                  'gojek', 'quite','fucking', 'every', 'getting', 'trying', 'told', 'something', 'singaporean', \n",
    "                  'feel', 'lta', 'fuck', 'without', 'let', 'made', 'getting', 'passenger', 'restaurant', 'grabfood', 'door', \n",
    "                  'merchant', 'don', 't', 'customer', 'cars', 'actually', 'senior', 'entrepreneur', 'rental', 'cars', 'current'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Functions to Preview Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "t = df_clean_cat_bcovid[df_clean_cat_bcovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'bus']\n",
    "\n",
    "print('===========================Bus Before Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_bcovid, stopwords, 'bus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "t = df_clean_cat_acovid[df_clean_cat_acovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'bus']\n",
    "\n",
    "print('===========================Bus After Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_acovid, stopwords, 'bus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "t = df_clean_cat_all[df_clean_cat_all['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'bus']\n",
    "\n",
    "print('===========================Bus Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_all, stopwords, 'bus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "t = df_clean_cat_bcovid[df_clean_cat_bcovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'mrt']\n",
    "\n",
    "print('===========================MRT Before Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_bcovid, stopwords, 'mrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "t = df_clean_cat_acovid[df_clean_cat_acovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'mrt']\n",
    "\n",
    "print('===========================MRT After Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_acovid, stopwords, 'mrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "t = df_clean_cat_all[df_clean_cat_all['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'mrt']\n",
    "\n",
    "print('===========================MRT Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_all, stopwords, 'mrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "t = df_clean_cat_bcovid[df_clean_cat_bcovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'taxi']\n",
    "\n",
    "print('===========================Taxi Before Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_bcovid, stopwords, 'taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "t = df_clean_cat_acovid[df_clean_cat_acovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'taxi']\n",
    "\n",
    "print('===========================Taxi After Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_acovid, stopwords, 'taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "t = df_clean_cat_all[df_clean_cat_all['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'taxi']\n",
    "\n",
    "print('===========================Taxi Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_all, stopwords, 'taxi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "t = df_clean_cat_bcovid[df_clean_cat_bcovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'private hire']\n",
    "\n",
    "print('===========================Private Hire Before Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_bcovid, stopwords, 'private hire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "t = df_clean_cat_acovid[df_clean_cat_acovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'private hire']\n",
    "\n",
    "print('===========================Private Hire After Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_acovid, stopwords, 'private hire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "t = df_clean_cat_all[df_clean_cat_all['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'private hire']\n",
    "\n",
    "print('===========================Private Hire Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_all, stopwords, 'private hire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Covid\n",
    "\n",
    "t = df_clean_cat_bcovid[df_clean_cat_bcovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'car rental']\n",
    "\n",
    "print('===========================Private Hire Before Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_bcovid, stopwords, 'car rental')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Covid\n",
    "\n",
    "t = df_clean_cat_acovid[df_clean_cat_acovid['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'car rental']\n",
    "\n",
    "print('===========================Private Hire After Covid Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_acovid, stopwords, 'car rental')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All\n",
    "\n",
    "t = df_clean_cat_all[df_clean_cat_all['sentiment']=='Negative']\n",
    "p = t[t['category'] == 'car rental']\n",
    "\n",
    "print('===========================Private Hire Title===========================')\n",
    "for index,row in p[:5].iterrows():\n",
    "    print(row['text'])\n",
    "wc_neg(df_clean_cat_all, stopwords, 'car rental')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below will export the sentiment dataframes for topic modelling\n",
    "# Do edit the code accordingly to state your preferred path file\n",
    "\n",
    "df_clean_cat_bcovid.to_csv(r'df_clean_cat_bcovid_sent.csv', index = False, encoding = 'utf-8-sig' )\n",
    "df_clean_cat_acovid.to_csv(r'df_clean_cat_acovid_sent.csv', index = False, encoding = 'utf-8-sig')\n",
    "df_clean_cat_all.to_csv(r'df_clean_cat_all_sent.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data needed for Dashboard\n",
    "\n",
    "Here, we will prepare the data for dashboard purposes.\n",
    "\n",
    "We will remove the stopwords in df_clean_cat_all dataframe before it will be loaded into PowerBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_wc_no_stopwords(data, stopwords):\n",
    "    output = []\n",
    "    output_df = data\n",
    "    #t = data[data['sentiment']=='Negative']\n",
    "    #p = t[t['category'] == cat]\n",
    "    \n",
    "    for text in data['text']:\n",
    "        s_text = text.split()\n",
    "        result_text = [word for word in s_text if word.lower() not in stopwords]\n",
    "        result = ' '.join(result_text)\n",
    "        output.append(result)\n",
    "\n",
    "    output_df['text'] = pd.Series(output)\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_cat_all_export = df_wc_no_stopwords(df_clean_cat_all, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code will export the file for dashboard\n",
    "# Do change the code accordingly to your preferred path file\n",
    "\n",
    "df_clean_cat_all_export.to_csv(r'df_clean_cat_all_export.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "097a94cc1bfc5a0a380b63d1eb45dc603bb0f63840061a2276c4020d01d7c102"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
